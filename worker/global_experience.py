#!/usr/bin/env python3
"""Cross-project experience storage and retrieval helpers."""

from __future__ import annotations

import os
import re
from contextlib import contextmanager
from datetime import datetime


GLOBAL_EXPERIENCE_DIR = os.environ.get("GLOBAL_EXPERIENCE_DIR", "/app/data/experience")
GLOBAL_PROGRESS_FILE = os.path.join(GLOBAL_EXPERIENCE_DIR, "GLOBAL_PROGRESS.md")
GLOBAL_LOCK_FILE = GLOBAL_PROGRESS_FILE + ".lock"

_GLOBAL_HEADER = (
    "# Global Development Experience\n\n"
    "Cross-project experience entries generated by Claude workers.\n\n"
    "---\n"
)

_STOP_WORDS = {
    "task", "tasks", "issue", "issues", "fix", "fixed", "feature", "update", "updates",
    "project", "projects", "work", "working", "change", "changes", "problem", "solution",
    "with", "from", "into", "that", "this", "these", "those", "have", "has", "had", "for",
    "and", "the", "use", "using", "used", "api", "app", "code", "tests", "test",
}


def _ensure_global_progress_file() -> None:
    os.makedirs(GLOBAL_EXPERIENCE_DIR, exist_ok=True)
    if not os.path.exists(GLOBAL_PROGRESS_FILE):
        with open(GLOBAL_PROGRESS_FILE, "w", encoding="utf-8") as f:
            f.write(_GLOBAL_HEADER)


@contextmanager
def _exclusive_lock():
    import fcntl

    os.makedirs(os.path.dirname(GLOBAL_LOCK_FILE), exist_ok=True)
    lock_f = open(GLOBAL_LOCK_FILE, "a+", encoding="utf-8")
    try:
        fcntl.flock(lock_f.fileno(), fcntl.LOCK_EX)
        yield
    finally:
        fcntl.flock(lock_f.fileno(), fcntl.LOCK_UN)
        lock_f.close()


def append_global_entry(
    *,
    project_id: str,
    project_name: str,
    task_id: str,
    task_title: str,
    local_entry: str,
) -> None:
    """Append a local experience entry into the shared global experience file."""
    if not project_id:
        return

    _ensure_global_progress_file()

    lines = [line.rstrip() for line in local_entry.strip().splitlines() if line.strip()]
    if lines and lines[0].startswith("## ["):
        body_lines = lines[1:]
    else:
        body_lines = lines

    if not body_lines:
        body_lines = [
            f"- **Completed**: {datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')}",
            "- **Problem**: N/A",
            "- **Solution**: Task completed.",
            "- **Prevention**: N/A",
        ]

    header = f"## [{project_id}/{task_id}] {task_title}"
    project_line = f"- **Project**: {project_name or project_id}"
    project_id_line = f"- **Project ID**: {project_id}"
    global_entry = "\n".join([header, project_line, project_id_line, *body_lines, ""]) + "\n"

    with _exclusive_lock():
        with open(GLOBAL_PROGRESS_FILE, "a", encoding="utf-8") as f:
            f.write(global_entry)


def _split_entries(content: str) -> list[str]:
    starts = [m.start() for m in re.finditer(r"^## \[", content, flags=re.MULTILINE)]
    if not starts:
        return []
    entries: list[str] = []
    for i, start in enumerate(starts):
        end = starts[i + 1] if i + 1 < len(starts) else len(content)
        block = content[start:end].strip()
        if block:
            entries.append(block)
    return entries


def _extract_project_id(entry: str) -> str:
    match = re.search(r"^- \*\*Project ID\*\*:\s*(.+)$", entry, flags=re.MULTILINE)
    if match:
        return match.group(1).strip()

    # Backward compatibility if metadata is missing.
    header = entry.splitlines()[0] if entry else ""
    match = re.match(r"^## \[([^/\]]+)/", header)
    if match:
        return match.group(1).strip()
    return ""


def _extract_query_terms(task_title: str, task_desc: str) -> list[str]:
    query = f"{task_title}\n{task_desc}".strip()
    if not query:
        return []

    lower = query.lower()
    ascii_terms = re.findall(r"[a-z0-9_/-]{3,}", lower)
    cjk_terms = re.findall(r"[\u4e00-\u9fff]{2,}", query)

    terms: list[str] = []
    seen: set[str] = set()

    for term in ascii_terms:
        if term in _STOP_WORDS:
            continue
        if term not in seen:
            seen.add(term)
            terms.append(term)

    for term in cjk_terms:
        if term not in seen:
            seen.add(term)
            terms.append(term)

    return terms[:20]


def _score_entry(entry: str, terms: list[str]) -> int:
    if not terms:
        return 0

    title = (entry.splitlines()[0] if entry else "").lower()
    body = entry.lower()
    score = 0
    for term in terms:
        probe = term.lower()
        if probe in title:
            score += 4
        elif probe in body:
            score += 2
    return score


def query_cross_project_experience(
    *,
    current_project_id: str,
    task_title: str,
    task_desc: str,
    max_entries: int = 3,
    max_chars: int = 2500,
) -> str:
    """Return relevant cross-project entries as markdown blocks."""
    if max_entries <= 0 or max_chars <= 0:
        return ""
    if not os.path.exists(GLOBAL_PROGRESS_FILE):
        return ""

    try:
        with open(GLOBAL_PROGRESS_FILE, "r", encoding="utf-8") as f:
            content = f.read()
    except Exception:
        return ""

    entries = _split_entries(content)
    if not entries:
        return ""

    terms = _extract_query_terms(task_title, task_desc)
    scored: list[tuple[int, int, str]] = []
    for idx, entry in enumerate(entries):
        if current_project_id and _extract_project_id(entry) == current_project_id:
            continue
        scored.append((_score_entry(entry, terms), idx, entry))

    if not scored:
        return ""

    matched = [row for row in scored if row[0] > 0]
    if matched:
        matched.sort(key=lambda row: (-row[0], -row[1]))  # score desc, newer first
        chosen = [row[2] for row in matched[:max_entries]]
    else:
        # No keyword hits: fallback to most recent entries from other projects.
        scored.sort(key=lambda row: -row[1])
        chosen = [row[2] for row in scored[:max_entries]]

    blocks: list[str] = []
    used = 0
    for entry in chosen:
        block = entry.strip()
        if not block:
            continue

        if blocks:
            sep = "\n\n---\n\n"
            if used + len(sep) >= max_chars:
                break
            blocks.append(sep)
            used += len(sep)

        remain = max_chars - used
        if remain <= 0:
            break
        if len(block) > remain:
            if remain < 200:
                break
            block = block[:remain].rstrip()

        blocks.append(block)
        used += len(block)

    return "".join(blocks).strip()

